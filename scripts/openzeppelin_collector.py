import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import requests
import pandas as pd
import json
import re
from datetime import datetime
from config.settings_template import GITHUB_TOKEN, OPENZEPPELIN_CONFIG


class OpenZeppelinCollector:
    def __init__(self):
        self.headers = {'Authorization': f'token {GITHUB_TOKEN}'}
        self.owner = OPENZEPPELIN_CONFIG['owner']
        self.repo = OPENZEPPELIN_CONFIG['repo']
        self.base_url = f"https://api.github.com/repos/{self.owner}/{self.repo}"

        # æ ¸å¿ƒbugä¿®å¤å…³é”®è¯ï¼ˆå¼ºä¿¡å·ï¼‰
        self.core_bug_keywords = [
            'bug', 'fix', 'defect', 'vulnerability', 'exploit', 'attack',
            'incorrect', 'wrong', 'fail', 'crash', 'revert', 'panic',
            'security', 'reentrancy', 'overflow', 'underflow'
        ]

        # æ’é™¤æ¨¡å¼ - æ˜ç¡®ä¸æ˜¯bugä¿®å¤çš„PRç±»å‹
        self.exclusion_patterns = [
            # ä¾èµ–å’Œå·¥å…·é“¾æ›´æ–°
            r'^bump\s+',
            r'^update\s+dependency',
            r'^upgrade\s+dependency',
            r'^\[deps\]',
            r'^chore\(deps\)',
            r'dependabot',
            r'renovate',

            # æ–‡æ¡£å’Œæ³¨é‡Š
            r'^docs?[\:\(]',
            r'^documentation',
            r'^\[docs?\]',
            r'^update.*readme',
            r'^fix.*typo',
            r'^typo',
            r'^comment',
            r'natspec',

            # æ ¼å¼åŒ–å’Œä»£ç é£æ ¼
            r'^format',
            r'^lint',
            r'^style',
            r'^prettier',
            r'^eslint',
            r'^cleanup',

            # æ„å»ºå’ŒCI/CD
            r'^ci[\:\(]',
            r'^build[\:\(]',
            r'^\[ci\]',
            r'github.*action',
            r'workflow',

            # ç‰ˆæœ¬å’Œå‘å¸ƒ
            r'^release',
            r'^version',
            r'^changelog',
            r'^prepare.*release',

            # æµ‹è¯•ï¼ˆé™¤éæ˜ç¡®æåˆ°fixï¼‰
            r'^test(?!.*fix)',
            r'^add.*test(?!.*fix)',

            # é‡æ„ï¼ˆé™¤éæ˜ç¡®æåˆ°fixï¼‰
            r'^refactor(?!.*fix)',
            r'^rename(?!.*fix)',
        ]

        # OpenZeppelinåˆçº¦ç‰¹å®šå…³é”®è¯
        self.oz_contract_keywords = [
            # ERCæ ‡å‡†
            'erc20', 'erc721', 'erc777', 'erc1155', 'erc1967', 'erc2612',
            'erc2771', 'erc3156', 'erc4626', 'token', 'nft',

            # è®¿é—®æ§åˆ¶
            'ownable', 'accesscontrol', 'role', 'permission',

            # å®‰å…¨æœºåˆ¶
            'reentrancyguard', 'pausable', 'nonreentrant',

            # ä»£ç†å’Œå‡çº§
            'proxy', 'upgradeable', 'uups', 'transparent', 'beacon',
            'initializable', 'storage collision',

            # æ•°å­¦
            'safemath', 'safeCast', 'math', 'checked arithmetic',

            # åŠ å¯†
            'ecdsa', 'signature', 'merkle', 'eip712',

            # æ²»ç†
            'governor', 'timelock', 'votes', 'voting',
        ]

        self.merged_prs = []

    def should_exclude_pr(self, pr):
        """åˆ¤æ–­PRæ˜¯å¦åº”è¯¥è¢«æ’é™¤ï¼ˆæ˜ç¡®ä¸æ˜¯bugä¿®å¤ï¼‰"""
        title = pr['title'].lower()
        user = pr['user'].lower()

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜¯bot
        bot_users = ['dependabot', 'renovate', 'dependabot-preview']
        if any(bot in user for bot in bot_users):
            return True

        # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ¹é…æ’é™¤æ¨¡å¼
        for pattern in self.exclusion_patterns:
            if re.match(pattern, title, re.IGNORECASE):
                return True

        # åªä¿®æ”¹éSolidityæ–‡ä»¶çš„PR
        changed_files = pr.get('changed_files', 0)
        if changed_files > 0:
            # å¦‚æœèƒ½è·å–åˆ°æ–‡ä»¶åˆ—è¡¨ä¼šæ›´å‡†ç¡®ï¼Œè¿™é‡Œç”¨å¯å‘å¼è§„åˆ™
            # å¦‚æœæ ‡é¢˜æåˆ°æ–‡æ¡£ã€ä¾èµ–ã€CIç­‰ï¼Œä¸”æ²¡æœ‰å¼ºbugå…³é”®è¯ï¼Œæ’é™¤
            non_code_indicators = ['readme', 'docs', 'package.json', 'lock', '.yml', '.yaml', '.md']
            if any(indicator in title for indicator in non_code_indicators):
                if not any(keyword in title for keyword in ['fix', 'bug', 'security', 'vulnerability']):
                    return True

        return False

    def calculate_bug_fix_score(self, pr):
        """è®¡ç®—bugä¿®å¤ç›¸å…³æ€§åˆ†æ•°ï¼ˆæ”¹è¿›çš„è¯„åˆ†ç³»ç»Ÿï¼‰"""
        title_lower = pr['title'].lower()
        body_lower = pr['body'].lower()
        labels_lower = [label.lower() for label in pr['labels']]

        score = 0
        evidence = {
            'strong_signals': [],
            'medium_signals': [],
            'weak_signals': [],
            'core_keywords': [],
            'oz_keywords': [],
            'labels': [],
            'issue_refs': []
        }

        # === å¼ºä¿¡å· (+5åˆ†æ¯ä¸ª) ===

        # 1. æ ‡ç­¾åŒ…å«bug/security/vulnerability
        security_labels = ['bug', 'security', 'vulnerability', 'critical', 'high-severity']
        found_labels = [label for label in labels_lower if any(sl in label for sl in security_labels)]
        if found_labels:
            score += 5 * len(found_labels)
            evidence['strong_signals'].append(f"Security labels: {found_labels}")
            evidence['labels'] = found_labels

        # 2. æ ‡é¢˜æ˜ç¡®åŒ…å« "fix" + bugå…³é”®è¯
        if 'fix' in title_lower:
            for keyword in ['bug', 'vulnerability', 'security', 'exploit', 'reentrancy', 'overflow', 'underflow']:
                if keyword in title_lower:
                    score += 5
                    evidence['strong_signals'].append(f"Title: 'fix' + '{keyword}'")
                    break

        # 3. æ­£æ–‡åŒ…å« "Fixes #æ•°å­—" æˆ– "Closes #æ•°å­—"
        issue_ref_patterns = [
            r'fixes?\s+#(\d+)',
            r'closes?\s+#(\d+)',
            r'resolves?\s+#(\d+)',
        ]
        for pattern in issue_ref_patterns:
            matches = re.findall(pattern, body_lower)
            if matches:
                score += 3 * len(matches)  # æ¯ä¸ªissueå¼•ç”¨+3åˆ†
                evidence['medium_signals'].append(f"Issue references: #{', #'.join(matches)}")
                evidence['issue_refs'] = matches
                break

        # 4. æ ‡é¢˜/æ­£æ–‡æ˜ç¡®æåˆ°ä¸¥é‡æ€§
        severity_keywords = ['critical', 'severe', 'high severity', 'security issue', 'vulnerability']
        for keyword in severity_keywords:
            if keyword in title_lower or keyword in body_lower:
                score += 4
                evidence['strong_signals'].append(f"Severity keyword: '{keyword}'")
                break

        # === ä¸­ç­‰ä¿¡å· (+2-3åˆ†) ===

        # 5. æ ¸å¿ƒbugå…³é”®è¯åŒ¹é…
        title_body_text = title_lower + ' ' + body_lower
        core_matches = [kw for kw in self.core_bug_keywords if kw in title_body_text]
        if core_matches:
            score += min(len(core_matches) * 2, 6)  # æœ€å¤š+6åˆ†
            evidence['medium_signals'].append(f"Core bug keywords: {core_matches[:3]}")
            evidence['core_keywords'] = core_matches[:5]

        # 6. OpenZeppelinåˆçº¦å…³é”®è¯ + bugç›¸å…³è¯
        oz_matches = [kw for kw in self.oz_contract_keywords if kw in title_body_text]
        if oz_matches and any(bug_kw in title_body_text for bug_kw in ['bug', 'fix', 'issue', 'incorrect', 'wrong']):
            score += 3
            evidence['medium_signals'].append(f"OZ keywords + bug context: {oz_matches[:2]}")
            evidence['oz_keywords'] = oz_matches[:3]

        # === å¼±ä¿¡å· (+1åˆ†) ===

        # 7. åŒ…å«é”™è¯¯/é—®é¢˜ç›¸å…³è¯ï¼Œä½†æ²¡æœ‰å¼ºä¿¡å·
        weak_keywords = ['error', 'problem', 'issue', 'incorrect', 'unexpected']
        weak_matches = [kw for kw in weak_keywords if kw in title_body_text]
        if weak_matches and not evidence['strong_signals']:
            score += len(weak_matches)
            evidence['weak_signals'].append(f"Weak keywords: {weak_matches[:2]}")

        # 8. ä»£ç å˜æ›´è§„æ¨¡åˆç†ï¼ˆbugä¿®å¤é€šå¸¸ä¸ä¼šç‰¹åˆ«å¤§ï¼‰
        additions = pr.get('additions', 0)
        deletions = pr.get('deletions', 0)
        total_changes = additions + deletions

        # ä¸­å°è§„æ¨¡å˜æ›´æ›´å¯èƒ½æ˜¯bugä¿®å¤
        if 10 <= total_changes <= 500:
            score += 1
            evidence['weak_signals'].append(f"Moderate code changes: {total_changes} lines")

        return score, evidence

    def collect_all_merged_prs(self):
        """æ”¶é›†æ‰€æœ‰å·²åˆå¹¶çš„PR"""
        print("ğŸ“¥ æ­£åœ¨æ”¶é›†OpenZeppelinæ‰€æœ‰å·²åˆå¹¶çš„PR...")
        print(f"ğŸ”— ä»“åº“: {self.owner}/{self.repo}")

        merged_prs = []
        page = 1
        total_collected = 0

        while True:
            print(f"   æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")

            prs = self.make_request(f"{self.base_url}/pulls", {
                'state': 'closed',
                'per_page': 100,
                'page': page,
                'sort': 'updated',
                'direction': 'desc'
            })

            if not prs:
                break

            page_merged_count = 0
            for pr in prs:
                if pr.get('merged_at') is not None:
                    merged_prs.append({
                        'project_name': 'OpenZeppelin',
                        'project_type': 'Smart Contract Library',
                        'project_domain': 'Reusable Solidity Security Contracts',
                        'number': pr['number'],
                        'title': pr['title'],
                        'body': pr.get('body', '') or '',
                        'state': pr['state'],
                        'merged_at': pr['merged_at'],
                        'created_at': pr['created_at'],
                        'user': pr['user']['login'],
                        'url': pr['html_url'],
                        'labels': [label['name'] for label in pr.get('labels', [])],
                        'commits': pr.get('commits', 0),
                        'additions': pr.get('additions', 0),
                        'deletions': pr.get('deletions', 0),
                        'changed_files': pr.get('changed_files', 0),
                        'assignees': [assignee['login'] for assignee in pr.get('assignees', [])],
                        'milestone': pr.get('milestone', {}).get('title', '') if pr.get('milestone') else '',
                        'base_ref': pr.get('base', {}).get('ref', ''),
                        'head_ref': pr.get('head', {}).get('ref', '')
                    })
                    page_merged_count += 1

            total_collected += page_merged_count
            print(f"   ç¬¬ {page} é¡µæ‰¾åˆ° {page_merged_count} ä¸ªåˆå¹¶çš„PR (æ€»è®¡: {total_collected})")

            if page_merged_count == 0:
                break

            page += 1

        print(f"âœ… æ€»å…±æ”¶é›†åˆ° {len(merged_prs)} ä¸ªå·²åˆå¹¶çš„PR")
        return merged_prs

    def analyze_merged_prs(self, merged_prs):
        """åˆ†æå·²åˆå¹¶çš„PR"""
        print("ğŸ“Š åˆ†æOpenZeppelinå·²åˆå¹¶çš„PR...")

        total_prs = len(merged_prs)

        # æ—¶é—´åˆ†æ
        dates = [pr['merged_at'][:10] for pr in merged_prs]
        date_counts = pd.Series(dates).value_counts().sort_index()

        # ç”¨æˆ·åˆ†æ
        users = [pr['user'] for pr in merged_prs]
        user_counts = pd.Series(users).value_counts()

        # æ ‡ç­¾åˆ†æ
        all_labels = []
        for pr in merged_prs:
            all_labels.extend(pr['labels'])
        label_counts = pd.Series(all_labels).value_counts()

        # ä»£ç å˜æ›´åˆ†æ
        total_additions = sum(pr['additions'] for pr in merged_prs)
        total_deletions = sum(pr['deletions'] for pr in merged_prs)
        total_files = sum(pr['changed_files'] for pr in merged_prs)

        print(f"ğŸ“ˆ OpenZeppelinç»Ÿè®¡ç»“æœ:")
        print(f"   - æ€»åˆå¹¶PRæ•°: {total_prs}")
        print(f"   - æœ€æ—©åˆå¹¶æ—¥æœŸ: {min(dates) if dates else 'N/A'}")
        print(f"   - æœ€æ™šåˆå¹¶æ—¥æœŸ: {max(dates) if dates else 'N/A'}")
        print(
            f"   - æœ€æ´»è·ƒè´¡çŒ®è€…: {user_counts.head(1).index[0] if not user_counts.empty else 'N/A'} ({user_counts.iloc[0] if not user_counts.empty else 0} PRs)")
        print(f"   - æ€»ä»£ç è¡Œå˜æ›´: +{total_additions:,} -{total_deletions:,}")
        print(f"   - æ€»æ–‡ä»¶å˜æ›´: {total_files:,}")

        return {
            'total_prs': total_prs,
            'date_counts': date_counts,
            'user_counts': user_counts,
            'label_counts': label_counts,
            'code_stats': {
                'additions': total_additions,
                'deletions': total_deletions,
                'files': total_files
            }
        }

    def identify_bug_fix_prs(self, merged_prs):
        """è¯†åˆ«bugä¿®å¤ç›¸å…³çš„PRï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        print("ğŸ” è¯†åˆ«OpenZeppelin bugä¿®å¤ç›¸å…³çš„PR...")
        print("   ä½¿ç”¨æ”¹è¿›çš„è¯„åˆ†ç³»ç»Ÿï¼Œæ’é™¤ébugä¿®å¤PR...")

        bug_candidates = []
        excluded_count = 0

        for pr in merged_prs:
            # ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
            if self.should_exclude_pr(pr):
                excluded_count += 1
                continue

            # ç¬¬äºŒæ­¥ï¼šè®¡ç®—bugä¿®å¤è¯„åˆ†
            score, evidence = self.calculate_bug_fix_score(pr)

            # åªä¿ç•™æœ‰ä¸€å®šåˆ†æ•°çš„PR
            if score >= 3:  # æœ€ä½é—¨æ§›ï¼š3åˆ†
                # æ ¹æ®åˆ†æ•°ç¡®å®šç½®ä¿¡åº¦
                if score >= 10:
                    confidence = 'high'
                elif score >= 6:
                    confidence = 'medium'
                else:
                    confidence = 'low'

                bug_candidates.append({
                    **pr,
                    'bug_fix_score': score,
                    'confidence': confidence,
                    'evidence': evidence,
                    'strong_signals': len(evidence['strong_signals']),
                    'medium_signals': len(evidence['medium_signals']),
                    'weak_signals': len(evidence['weak_signals']),
                })

        # æŒ‰åˆ†æ•°é™åºæ’åº
        bug_candidates.sort(key=lambda x: x['bug_fix_score'], reverse=True)

        print(f"âœ… ä» {len(merged_prs)} ä¸ªåˆå¹¶PRä¸­è¯†åˆ«å‡º {len(bug_candidates)} ä¸ªç–‘ä¼¼bugä¿®å¤PR")
        print(f"   æ’é™¤äº† {excluded_count} ä¸ªæ˜ç¡®ébugä¿®å¤çš„PRï¼ˆä¾èµ–æ›´æ–°ã€æ–‡æ¡£ç­‰ï¼‰")

        # æŒ‰ç½®ä¿¡åº¦åˆ†ç±»
        high_confidence = len([c for c in bug_candidates if c['confidence'] == 'high'])
        medium_confidence = len([c for c in bug_candidates if c['confidence'] == 'medium'])
        low_confidence = len([c for c in bug_candidates if c['confidence'] == 'low'])

        print(f"\n   ç½®ä¿¡åº¦åˆ†å¸ƒ:")
        print(f"   - é«˜ç½®ä¿¡åº¦ (â‰¥10åˆ†): {high_confidence}")
        print(f"   - ä¸­ç½®ä¿¡åº¦ (6-9åˆ†): {medium_confidence}")
        print(f"   - ä½ç½®ä¿¡åº¦ (3-5åˆ†): {low_confidence}")

        # æ˜¾ç¤ºTop 10 bugä¿®å¤PR
        print(f"\n   ğŸ† Top 10 bugä¿®å¤å€™é€‰PR:")
        for i, candidate in enumerate(bug_candidates[:10], 1):
            print(f"   {i}. #{candidate['number']} (åˆ†æ•°: {candidate['bug_fix_score']}): {candidate['title'][:60]}")

        return bug_candidates

    def export_results(self, merged_prs, bug_candidates, stats):
        """å¯¼å‡ºç»“æœåˆ°Excel"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        excel_dir = os.path.abspath(OPENZEPPELIN_CONFIG['excel_output'])
        os.makedirs(excel_dir, exist_ok=True)

        excel_file = os.path.join(excel_dir, f"openzeppelin_{timestamp}.xlsx")

        print(f"\nğŸ“‚ æ­£åœ¨åˆ›å»ºExcelæ–‡ä»¶...")
        print(f"   ç›®å½•: {excel_dir}")
        print(f"   æ–‡ä»¶: openzeppelin_{timestamp}.xlsx")

        try:
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                # 1. æ‰€æœ‰åˆå¹¶çš„PR
                merged_df = pd.DataFrame(merged_prs)
                merged_df.to_excel(writer, sheet_name='All_Merged_PRs', index=False)

                # 2. bugä¿®å¤å€™é€‰PRï¼ˆæŒ‰åˆ†æ•°æ’åºï¼‰
                if bug_candidates:
                    bug_df = pd.DataFrame(bug_candidates)

                    # å‡†å¤‡æ˜¾ç¤ºåˆ—
                    display_columns = [
                        'number', 'title', 'user', 'merged_at',
                        'bug_fix_score', 'confidence', 'strong_signals', 'medium_signals',
                        'url', 'labels', 'additions', 'deletions', 'changed_files'
                    ]

                    bug_display_df = bug_df[display_columns].copy()
                    bug_display_df['labels'] = bug_display_df['labels'].apply(lambda x: ', '.join(x) if x else '')

                    bug_display_df.to_excel(writer, sheet_name='Bug_Fix_Candidates', index=False)

                    # 3. è¯¦ç»†è¯æ®è¡¨
                    evidence_data = []
                    for candidate in bug_candidates:
                        ev = candidate['evidence']
                        evidence_data.append({
                            'PR_Number': candidate['number'],
                            'Title': candidate['title'],
                            'Score': candidate['bug_fix_score'],
                            'Confidence': candidate['confidence'],
                            'Strong_Signals': '; '.join(ev['strong_signals']),
                            'Medium_Signals': '; '.join(ev['medium_signals']),
                            'Weak_Signals': '; '.join(ev['weak_signals']),
                            'Core_Keywords': ', '.join(ev['core_keywords'][:5]),
                            'OZ_Keywords': ', '.join(ev['oz_keywords'][:5]),
                            'Labels': ', '.join(ev['labels']),
                            'Issue_Refs': ', '.join([f"#{ref}" for ref in ev['issue_refs']])
                        })

                    evidence_df = pd.DataFrame(evidence_data)
                    evidence_df.to_excel(writer, sheet_name='Evidence_Details', index=False)

                # 4. ç»Ÿè®¡ä¿¡æ¯
                stats_data = [
                    ['é¡¹ç›®åç§°', 'OpenZeppelin'],
                    ['é¡¹ç›®ç±»å‹', 'Smart Contract Library'],
                    ['é¡¹ç›®é¢†åŸŸ', 'Reusable Solidity Security Contracts'],
                    ['ä»“åº“åœ°å€', f"{self.owner}/{self.repo}"],
                    ['æ€»åˆå¹¶PRæ•°', stats['total_prs']],
                    ['ç–‘ä¼¼bugä¿®å¤PRæ•°', len(bug_candidates)],
                    ['é«˜ç½®ä¿¡åº¦bugä¿®å¤', len([c for c in bug_candidates if c['confidence'] == 'high'])],
                    ['ä¸­ç½®ä¿¡åº¦bugä¿®å¤', len([c for c in bug_candidates if c['confidence'] == 'medium'])],
                    ['ä½ç½®ä¿¡åº¦bugä¿®å¤', len([c for c in bug_candidates if c['confidence'] == 'low'])],
                    ['æœ€æ´»è·ƒè´¡çŒ®è€…', stats['user_counts'].index[0] if not stats['user_counts'].empty else 'N/A'],
                    ['æ€»ä»£ç å¢åŠ è¡Œæ•°', stats['code_stats']['additions']],
                    ['æ€»ä»£ç åˆ é™¤è¡Œæ•°', stats['code_stats']['deletions']],
                    ['æ€»å˜æ›´æ–‡ä»¶æ•°', stats['code_stats']['files']]
                ]

                stats_df = pd.DataFrame(stats_data, columns=['æŒ‡æ ‡', 'æ•°å€¼'])
                stats_df.to_excel(writer, sheet_name='Statistics', index=False)

                # 5. åˆ†æ•°åˆ†å¸ƒ
                if bug_candidates:
                    score_ranges = {
                        '15+åˆ† (æé«˜)': len([c for c in bug_candidates if c['bug_fix_score'] >= 15]),
                        '10-14åˆ† (é«˜)': len([c for c in bug_candidates if 10 <= c['bug_fix_score'] < 15]),
                        '6-9åˆ† (ä¸­)': len([c for c in bug_candidates if 6 <= c['bug_fix_score'] < 10]),
                        '3-5åˆ† (ä½)': len([c for c in bug_candidates if 3 <= c['bug_fix_score'] < 6]),
                    }

                    score_df = pd.DataFrame(list(score_ranges.items()), columns=['åˆ†æ•°åŒºé—´', 'æ•°é‡'])
                    score_df.to_excel(writer, sheet_name='Score_Distribution', index=False)

            if os.path.exists(excel_file):
                file_size = os.path.getsize(excel_file)
                print(f"âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼")
                print(f"   å¤§å°: {file_size:,} bytes")
            else:
                print(f"âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºExcelæ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            excel_file = None

        print(f"ğŸ“ OpenZeppelinç»“æœå·²å¯¼å‡ºåˆ°: {excel_file}")
        print(f"ğŸ“‚ å®Œæ•´è·¯å¾„: {os.path.abspath(excel_file) if excel_file else 'N/A'}")
        return excel_file

    def make_request(self, url, params=None):
        """å‘é€APIè¯·æ±‚"""
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 403:
                print("âš ï¸  APIé…é¢å¯èƒ½ä¸è¶³ï¼Œè¯·ç¨åé‡è¯•")
                return None
            else:
                print(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
        except Exception as e:
            print(f"è¯·æ±‚å¼‚å¸¸: {e}")
            return None

    def run_collection(self):
        """è¿è¡Œå®Œæ•´çš„æ”¶é›†æµç¨‹"""
        print("ğŸš€ å¼€å§‹æ”¶é›†OpenZeppelinå·²åˆå¹¶çš„PR...")
        print("ğŸ“– å®éªŒæµç¨‹ï¼šä¸“é—¨åˆ†æSolidityæ™ºèƒ½åˆçº¦åº“")
        print("ğŸ”— é¡¹ç›®ï¼šOpenZeppelin - å¯é‡ç”¨çš„å®‰å…¨æ™ºèƒ½åˆçº¦æ ‡å‡†")
        print(f"ğŸ“ ä»“åº“ï¼š{self.owner}/{self.repo}")
        print("\nğŸ¯ æ”¹è¿›çš„bugè¯†åˆ«ç­–ç•¥ï¼š")
        print("   âœ… æ’é™¤ï¼šä¾èµ–æ›´æ–°ã€æ–‡æ¡£ä¿®æ”¹ã€æ ¼å¼åŒ–ã€CI/CDç­‰")
        print("   âœ… å¼ºä¿¡å·ï¼šsecurityæ ‡ç­¾ã€fix+bugå…³é”®è¯ã€issueå¼•ç”¨")
        print("   âœ… è¯„åˆ†ç³»ç»Ÿï¼šå¼ºä¿¡å·5åˆ†ã€ä¸­ç­‰ä¿¡å·2-3åˆ†ã€å¼±ä¿¡å·1åˆ†")
        print("   âœ… æŒ‰åˆ†æ•°æ’åºï¼šè®©çœŸæ­£çš„bugä¿®å¤æ’åœ¨å‰é¢\n")

        # 1. æ”¶é›†æ‰€æœ‰å·²åˆå¹¶çš„PR
        merged_prs = self.collect_all_merged_prs()

        if not merged_prs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å·²åˆå¹¶çš„PR")
            return

        # 2. åˆ†æPRæ•°æ®
        stats = self.analyze_merged_prs(merged_prs)

        # 3. è¯†åˆ«bugä¿®å¤ç›¸å…³çš„PRï¼ˆæ”¹è¿›ç‰ˆï¼‰
        bug_candidates = self.identify_bug_fix_prs(merged_prs)

        # 4. å¯¼å‡ºç»“æœ
        excel_file = self.export_results(merged_prs, bug_candidates, stats)

        print(f"\nâœ… OpenZeppelinæ•°æ®æ”¶é›†å®Œæˆï¼")
        print(f"ğŸ“Š ç»“æœæ‘˜è¦:")
        print(f"   - é¡¹ç›®: OpenZeppelin")
        print(f"   - æ€»åˆå¹¶PR: {len(merged_prs)}")
        print(f"   - ç–‘ä¼¼bugä¿®å¤: {len(bug_candidates)}")
        print(f"   - é«˜ç½®ä¿¡åº¦: {len([c for c in bug_candidates if c['confidence'] == 'high'])}")
        print(f"   - ç»“æœæ–‡ä»¶: {excel_file}")

        print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print(f"   1. ä¼˜å…ˆå®¡æ ¸é«˜åˆ†æ•°ï¼ˆâ‰¥10åˆ†ï¼‰çš„PR")
        print(f"   2. æŸ¥çœ‹Evidence_Detailså·¥ä½œè¡¨äº†è§£è¯„åˆ†ä¾æ®")
        print(f"   3. ç¡®è®¤çœŸæ­£çš„bugä¿®å¤å®ä¾‹")
        print(f"   4. æŒ‰DASPå’Œæ™ºèƒ½åˆçº¦ç‰¹æœ‰ç¼ºé™·åˆ†ç±»")


if __name__ == "__main__":
    collector = OpenZeppelinCollector()
    collector.run_collection()