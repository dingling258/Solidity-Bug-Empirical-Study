import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import requests
import pandas as pd
import json
import re
from datetime import datetime
from config.settings_template import GITHUB_TOKEN, ZKSYNC_CONFIG


class zkSyncEraCollector:
    def __init__(self):
        self.headers = {'Authorization': f'token {GITHUB_TOKEN}'}
        self.owner = ZKSYNC_CONFIG['owner']
        self.repo = ZKSYNC_CONFIG['repo']
        self.base_url = f"https://api.github.com/repos/{self.owner}/{self.repo}"

        # é€šç”¨bugç›¸å…³å…³é”®è¯ï¼ˆä¸åŸç ”ç©¶ä¿æŒä¸€è‡´ï¼‰
        self.general_bug_keywords = [
            'bug', 'fix', 'repair', 'defect', 'vulnerability', 'issue',
            'error', 'problem', 'incorrect', 'wrong', 'fail', 'crash',
            'security', 'exploit', 'attack', 'overflow', 'underflow',
            'reentrancy', 'gas', 'optimization', 'revert', 'panic'
        ]

        # zkSync Eraç‰¹å®šå…³é”®è¯
        self.zksync_keywords = [
            # æ ¸å¿ƒLayer 2æ¦‚å¿µ
            'rollup', 'layer2', 'l2', 'l1', 'sequencer', 'batch', 'commit',
            'prove', 'execute', 'finalize', 'finalization', 'verification',

            # é›¶çŸ¥è¯†è¯æ˜ç›¸å…³
            'zkproof', 'proof', 'prover', 'verifier', 'circuit', 'witness',
            'plonk', 'recursion', 'aggregation', 'snark', 'stark', 'commitment',
            'merkle', 'polynomial', 'constraint', 'trusted', 'setup',

            # zkEVMå’Œè™šæ‹Ÿæœº
            'zkevm', 'vm', 'virtual', 'machine', 'opcode', 'bytecode',
            'execution', 'trace', 'memory', 'storage', 'stack', 'precompile',
            'intrinsic', 'simulation', 'interpreter', 'compilation',

            # æ¡¥æ¥å’Œè·¨é“¾
            'bridge', 'deposit', 'withdrawal', 'l1tol2', 'l2tol1', 'message',
            'cross', 'chain', 'mailbox', 'priority', 'queue', 'relay',
            'confirm', 'portal', 'messenger', 'transfer', 'lock', 'mint', 'burn',

            # è´¦æˆ·æŠ½è±¡
            'account', 'abstraction', 'aa', 'paymaster', 'factory', 'wallet',
            'signature', 'validation', 'nonce', 'sponsor', 'meta', 'transaction',
            'userops', 'operation', 'bundler', 'entrypoint', 'paymasterflow',

            # äº¤æ˜“å’Œæ‰¹æ¬¡å¤„ç†
            'transaction', 'tx', 'batch', 'commit', 'prove', 'execute',
            'priority', 'l2block', 'bootloader', 'compressed', 'calldata',
            'pubdata', 'overhead', 'encoding', 'decoding', 'hash',

            # Gaså’Œè´¹ç”¨æœºåˆ¶
            'gas', 'fee', 'limit', 'price', 'estimation', 'computation',
            'ergs', 'cost', 'refund', 'surplus', 'overhead', 'intrinsic',
            'l2gas', 'l1gas', 'compensation', 'pricing', 'metering',

            # çŠ¶æ€ç®¡ç†
            'state', 'diff', 'tree', 'root', 'leaf', 'branch', 'node',
            'sparse', 'patricia', 'storage', 'commitment', 'update',
            'transition', 'snapshot', 'checkpoint', 'rollback', 'revert',

            # ç³»ç»Ÿåˆçº¦
            'system', 'contract', 'deployer', 'compressor', 'known',
            'code', 'hash', 'registry', 'force', 'deploy', 'immutable',
            'simulator', 'context', 'meta', 'call', 'mimic',

            # å‡çº§å’Œæ²»ç†
            'upgrade', 'governance', 'admin', 'diamond', 'facet', 'proxy',
            'implementation', 'transparent', 'beacon', 'timelock', 'delay',
            'proposal', 'execution', 'shadow', 'freeze', 'unfreeze',

            # éªŒè¯å’Œæ ¡éªŒ
            'verify', 'validation', 'check', 'ensure', 'require', 'assert',
            'invariant', 'constraint', 'condition', 'precondition', 'postcondition',
            'safety', 'liveness', 'soundness', 'completeness', 'correctness',

            # ç½‘ç»œå’ŒåŒæ­¥
            'sync', 'reorg', 'fork', 'chain', 'head', 'canonical', 'consensus',
            'peer', 'network', 'protocol', 'handshake', 'discovery', 'gossip',
            'mempool', 'pending', 'confirmed', 'finalized', 'orphan',

            # å­˜å‚¨å’Œæ•°æ®ç»“æ„
            'storage', 'slot', 'key', 'value', 'mapping', 'array', 'struct',
            'packed', 'unpacked', 'layout', 'offset', 'size', 'alignment',
            'compression', 'decompression', 'serialization', 'encoding',

            # å¯†ç å­¦å’Œå®‰å…¨
            'crypto', 'hash', 'keccak', 'sha256', 'ecdsa', 'secp256k1',
            'signature', 'recovery', 'address', 'public', 'private', 'key',
            'random', 'nonce', 'salt', 'entropy', 'secure', 'audit',

            # zkSyncç‰¹æœ‰ç»„ä»¶
            'zksync', 'era', 'matter', 'labs', 'boojum', 'circuit',
            'fri', 'goldilocks', 'poseidon', 'rescue', 'algebraic', 'field'
        ]

        # åˆå¹¶æ‰€æœ‰å…³é”®è¯
        self.bug_keywords = self.general_bug_keywords + self.zksync_keywords

        self.merged_prs = []

    def collect_all_merged_prs(self):
        """æ”¶é›†æ‰€æœ‰å·²åˆå¹¶çš„PR"""
        print("ğŸ“¥ æ­£åœ¨æ”¶é›†zkSync Eraæ‰€æœ‰å·²åˆå¹¶çš„PR...")
        print(f"ğŸ”— ä»“åº“: {self.owner}/{self.repo}")

        merged_prs = []
        page = 1
        total_collected = 0

        while True:
            print(f"   æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")

            # åªè·å–mergedçŠ¶æ€çš„PR
            prs = self.make_request(f"{self.base_url}/pulls", {
                'state': 'closed',  # GitHub API: closedåŒ…å«mergedå’Œæœªmergedçš„
                'per_page': 100,
                'page': page,
                'sort': 'updated',
                'direction': 'desc'
            })

            if not prs:
                break

            # ç­›é€‰å‡ºçœŸæ­£mergedçš„PR
            page_merged_count = 0
            for pr in prs:
                if pr.get('merged_at') is not None:  # å…³é”®ï¼šåªè¦merged_atä¸ä¸ºç©º
                    merged_prs.append({
                        'project_name': 'zkSync Era',
                        'project_type': 'Layer 2',
                        'project_domain': 'Ethereum ZK-Rollup Scaling Solution',
                        'number': pr['number'],
                        'title': pr['title'],
                        'body': pr.get('body', '') or '',
                        'state': pr['state'],
                        'merged_at': pr['merged_at'],
                        'created_at': pr['created_at'],
                        'user': pr['user']['login'],
                        'url': pr['html_url'],
                        'labels': [label['name'] for label in pr.get('labels', [])],
                        'commits': pr.get('commits', 0),
                        'additions': pr.get('additions', 0),
                        'deletions': pr.get('deletions', 0),
                        'changed_files': pr.get('changed_files', 0),
                        'assignees': [assignee['login'] for assignee in pr.get('assignees', [])],
                        'milestone': pr.get('milestone', {}).get('title', '') if pr.get('milestone') else '',
                        'base_ref': pr.get('base', {}).get('ref', ''),
                        'head_ref': pr.get('head', {}).get('ref', '')
                    })
                    page_merged_count += 1

            total_collected += page_merged_count
            print(f"   ç¬¬ {page} é¡µæ‰¾åˆ° {page_merged_count} ä¸ªåˆå¹¶çš„PR (æ€»è®¡: {total_collected})")

            # å¦‚æœè¿™ä¸€é¡µæ²¡æœ‰mergedçš„PRï¼Œå¯èƒ½å·²ç»åˆ°åº•äº†
            if page_merged_count == 0:
                break

            page += 1

        print(f"âœ… æ€»å…±æ”¶é›†åˆ° {len(merged_prs)} ä¸ªå·²åˆå¹¶çš„PR")
        return merged_prs

    def analyze_merged_prs(self, merged_prs):
        """åˆ†æå·²åˆå¹¶çš„PR"""
        print("ğŸ“Š åˆ†æzkSync Eraå·²åˆå¹¶çš„PR...")

        # åŸºæœ¬ç»Ÿè®¡
        total_prs = len(merged_prs)

        # æ—¶é—´åˆ†æ
        dates = [pr['merged_at'][:10] for pr in merged_prs]
        date_counts = pd.Series(dates).value_counts().sort_index()

        # ç”¨æˆ·åˆ†æ
        users = [pr['user'] for pr in merged_prs]
        user_counts = pd.Series(users).value_counts()

        # æ ‡ç­¾åˆ†æ
        all_labels = []
        for pr in merged_prs:
            all_labels.extend(pr['labels'])
        label_counts = pd.Series(all_labels).value_counts()

        # ä»£ç å˜æ›´åˆ†æ
        total_additions = sum(pr['additions'] for pr in merged_prs)
        total_deletions = sum(pr['deletions'] for pr in merged_prs)
        total_files = sum(pr['changed_files'] for pr in merged_prs)

        # zkSync Eraç‰¹å®šåˆ†æ
        zk_proof_keywords = ['proof', 'prover', 'verifier', 'circuit', 'plonk', 'recursion', 'aggregation']
        bridge_keywords = ['bridge', 'deposit', 'withdrawal', 'l1tol2', 'l2tol1', 'cross', 'chain']
        aa_keywords = ['account', 'abstraction', 'paymaster', 'factory', 'userops', 'sponsor']
        gas_keywords = ['gas', 'fee', 'ergs', 'estimation', 'pricing', 'computation', 'overhead']
        batch_keywords = ['batch', 'commit', 'prove', 'execute', 'sequencer', 'priority', 'bootloader']
        upgrade_keywords = ['upgrade', 'governance', 'diamond', 'facet', 'proxy', 'timelock']

        zk_proof_prs = [pr for pr in merged_prs
                        if any(keyword in pr['title'].lower() or keyword in pr['body'].lower()
                               for keyword in zk_proof_keywords)]

        bridge_prs = [pr for pr in merged_prs
                      if any(keyword in pr['title'].lower() or keyword in pr['body'].lower()
                             for keyword in bridge_keywords)]

        aa_prs = [pr for pr in merged_prs
                  if any(keyword in pr['title'].lower() or keyword in pr['body'].lower()
                         for keyword in aa_keywords)]

        gas_prs = [pr for pr in merged_prs
                   if any(keyword in pr['title'].lower() or keyword in pr['body'].lower()
                          for keyword in gas_keywords)]

        batch_prs = [pr for pr in merged_prs
                     if any(keyword in pr['title'].lower() or keyword in pr['body'].lower()
                            for keyword in batch_keywords)]

        upgrade_prs = [pr for pr in merged_prs
                       if any(keyword in pr['title'].lower() or keyword in pr['body'].lower()
                              for keyword in upgrade_keywords)]

        print(f"ğŸ“ˆ zkSync Eraç»Ÿè®¡ç»“æœ:")
        print(f"   - æ€»åˆå¹¶PRæ•°: {total_prs}")
        print(f"   - ZKè¯æ˜ç›¸å…³PRæ•°: {len(zk_proof_prs)}")
        print(f"   - æ¡¥æ¥ç›¸å…³PRæ•°: {len(bridge_prs)}")
        print(f"   - è´¦æˆ·æŠ½è±¡ç›¸å…³PRæ•°: {len(aa_prs)}")
        print(f"   - Gas/è´¹ç”¨ç›¸å…³PRæ•°: {len(gas_prs)}")
        print(f"   - æ‰¹æ¬¡å¤„ç†ç›¸å…³PRæ•°: {len(batch_prs)}")
        print(f"   - å‡çº§æ²»ç†ç›¸å…³PRæ•°: {len(upgrade_prs)}")
        print(f"   - æœ€æ—©åˆå¹¶æ—¥æœŸ: {min(dates) if dates else 'N/A'}")
        print(f"   - æœ€æ™šåˆå¹¶æ—¥æœŸ: {max(dates) if dates else 'N/A'}")
        print(
            f"   - æœ€æ´»è·ƒè´¡çŒ®è€…: {user_counts.head(1).index[0] if not user_counts.empty else 'N/A'} ({user_counts.iloc[0] if not user_counts.empty else 0} PRs)")
        print(f"   - æ€»ä»£ç è¡Œå˜æ›´: +{total_additions:,} -{total_deletions:,}")
        print(f"   - æ€»æ–‡ä»¶å˜æ›´: {total_files:,}")

        return {
            'total_prs': total_prs,
            'zk_proof_prs': len(zk_proof_prs),
            'bridge_prs': len(bridge_prs),
            'aa_prs': len(aa_prs),
            'gas_prs': len(gas_prs),
            'batch_prs': len(batch_prs),
            'upgrade_prs': len(upgrade_prs),
            'date_counts': date_counts,
            'user_counts': user_counts,
            'label_counts': label_counts,
            'code_stats': {
                'additions': total_additions,
                'deletions': total_deletions,
                'files': total_files
            }
        }

    def identify_bug_fix_prs(self, merged_prs):
        """ä»å·²åˆå¹¶çš„PRä¸­è¯†åˆ«bugä¿®å¤ç›¸å…³çš„PRï¼ˆéµå¾ªåŸç ”ç©¶æ–¹æ³•è®ºï¼‰"""
        print("ğŸ” è¯†åˆ«zkSync Era bugä¿®å¤ç›¸å…³çš„PR...")

        bug_candidates = []

        for pr in merged_prs:
            title_lower = pr['title'].lower()
            body_lower = pr['body'].lower()
            labels_lower = [label.lower() for label in pr['labels']]

            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            title_body_text = title_lower + ' ' + body_lower

            # é€šç”¨bugå…³é”®è¯åŒ¹é…
            general_keyword_matches = [kw for kw in self.general_bug_keywords if kw in title_body_text]

            # zkSync Eraç‰¹å®šå…³é”®è¯åŒ¹é…
            zksync_keyword_matches = [kw for kw in self.zksync_keywords if kw in title_body_text]

            # æ£€æŸ¥æ ‡ç­¾
            bug_labels = ['bug', 'defect', 'security', 'vulnerability', 'fix', 'hotfix', 'patch', 'critical']
            label_matches = [label for label in labels_lower if any(bug_label in label for bug_label in bug_labels)]

            # æ£€æŸ¥fixå¼•ç”¨æ¨¡å¼
            fix_patterns = [
                r'fix(?:es)?\s*#?\d+',  # fixes #123
                r'resolv(?:es)?\s*#?\d+',  # resolves #123
                r'clos(?:es)?\s*#?\d+',  # closes #123
                r'fix(?:es)?\s+\w+',  # fixes bug
                r'patch(?:es)?\s+\w+',  # patches issue
            ]
            fix_references = []
            for pattern in fix_patterns:
                fix_references.extend(re.findall(pattern, title_body_text))

            # zkSync Eraç‰¹å®šçš„bugæ¨¡å¼
            zksync_bug_patterns = [
                # è¯æ˜ç³»ç»Ÿbug
                r'proof.*(?:fail|error|bug|invalid|generation|verification)',
                r'prover.*(?:fail|error|bug|crash|timeout|memory|overflow)',
                r'verifier.*(?:fail|error|bug|invalid|reject|accept|wrong)',
                r'circuit.*(?:fail|error|bug|constraint|synthesis|compile)',
                r'plonk.*(?:fail|error|bug|setup|commitment|polynomial)',
                r'recursion.*(?:fail|error|bug|aggregation|proof|depth)',
                r'witness.*(?:fail|error|bug|generation|invalid|missing)',

                # zkEVMç›¸å…³bug
                r'zkevm.*(?:fail|error|bug|execution|trace|opcode|bytecode)',
                r'vm.*(?:fail|error|bug|execution|memory|storage|stack)',
                r'opcode.*(?:fail|error|bug|implementation|execution|gas)',
                r'precompile.*(?:fail|error|bug|call|result|gas|revert)',
                r'bytecode.*(?:fail|error|bug|compilation|deployment|hash)',
                r'execution.*(?:fail|error|bug|trace|revert|panic|out)',
                r'memory.*(?:fail|error|bug|allocation|access|overflow)',
                r'storage.*(?:fail|error|bug|access|write|read|slot|key)',

                # æ¡¥æ¥ç›¸å…³bug
                r'bridge.*(?:fail|error|bug|deposit|withdrawal|transfer)',
                r'deposit.*(?:fail|error|bug|amount|token|l1|l2|stuck)',
                r'withdrawal.*(?:fail|error|bug|proof|finalization|delay)',
                r'l1tol2.*(?:fail|error|bug|message|relay|execution)',
                r'l2tol1.*(?:fail|error|bug|message|proof|inclusion)',
                r'mailbox.*(?:fail|error|bug|queue|priority|execution)',
                r'cross.*chain.*(?:fail|error|bug|message|sync|state)',
                r'portal.*(?:fail|error|bug|entry|exit|validation)',

                # è´¦æˆ·æŠ½è±¡bug
                r'account.*abstraction.*(?:fail|error|bug|validation)',
                r'paymaster.*(?:fail|error|bug|sponsor|fee|validation|flow)',
                r'factory.*(?:fail|error|bug|deployment|creation|salt)',
                r'userops.*(?:fail|error|bug|bundler|execution|validation)',
                r'signature.*(?:fail|error|bug|validation|recovery|invalid)',
                r'nonce.*(?:fail|error|bug|management|sequence|replay)',
                r'meta.*transaction.*(?:fail|error|bug|execution|sponsor)',

                # Gaså’Œè´¹ç”¨bug
                r'gas.*(?:fail|error|bug|estimation|limit|price|computation)',
                r'ergs.*(?:fail|error|bug|calculation|conversion|limit)',
                r'fee.*(?:fail|error|bug|calculation|payment|refund|sponsor)',
                r'overhead.*(?:fail|error|bug|calculation|l1|l2|pubdata)',
                r'intrinsic.*(?:fail|error|bug|gas|cost|calculation)',
                r'pricing.*(?:fail|error|bug|model|calculation|update)',
                r'refund.*(?:fail|error|bug|calculation|excess|surplus)',

                # æ‰¹æ¬¡å¤„ç†bug
                r'batch.*(?:fail|error|bug|commit|prove|execute|priority)',
                r'sequencer.*(?:fail|error|bug|ordering|inclusion|reorg)',
                r'commit.*(?:fail|error|bug|hash|data|compression|pubdata)',
                r'prove.*(?:fail|error|bug|generation|aggregation|time)',
                r'execute.*(?:fail|error|bug|transaction|block|bootloader)',
                r'priority.*(?:fail|error|bug|queue|ordering|timeout)',
                r'bootloader.*(?:fail|error|bug|execution|gas|memory)',
                r'compressed.*(?:fail|error|bug|data|encoding|decoding)',

                # çŠ¶æ€ç®¡ç†bug
                r'state.*(?:fail|error|bug|transition|diff|tree|root)',
                r'merkle.*(?:fail|error|bug|tree|proof|root|leaf|path)',
                r'storage.*tree.*(?:fail|error|bug|update|commit|sparse)',
                r'diff.*(?:fail|error|bug|calculation|compression|application)',
                r'rollback.*(?:fail|error|bug|revert|state|transaction)',
                r'checkpoint.*(?:fail|error|bug|creation|restoration)',
                r'snapshot.*(?:fail|error|bug|state|inconsistent|corrupt)',

                # å‡çº§å’Œæ²»ç†bug
                r'upgrade.*(?:fail|error|bug|proxy|implementation|diamond)',
                r'governance.*(?:fail|error|bug|proposal|execution|timelock)',
                r'diamond.*(?:fail|error|bug|facet|cut|selector|storage)',
                r'proxy.*(?:fail|error|bug|delegate|call|storage|collision)',
                r'timelock.*(?:fail|error|bug|delay|execution|cancel)',
                r'freeze.*(?:fail|error|bug|emergency|unfreeze|governance)',

                # åŒæ­¥å’Œç½‘ç»œbug
                r'sync.*(?:fail|error|bug|block|state|peer|network)',
                r'reorg.*(?:fail|error|bug|chain|canonical|fork|handle)',
                r'fork.*(?:fail|error|bug|choice|resolution|consensus)',
                r'consensus.*(?:fail|error|bug|agreement|finality|safety)',
                r'mempool.*(?:fail|error|bug|transaction|ordering|full)',
                r'pending.*(?:fail|error|bug|transaction|inclusion|timeout)',

                # å¯†ç å­¦ç›¸å…³bug
                r'hash.*(?:fail|error|bug|collision|preimage|keccak|sha)',
                r'signature.*(?:fail|error|bug|ecdsa|recovery|malleability)',
                r'address.*(?:fail|error|bug|derivation|collision|zero)',
                r'random.*(?:fail|error|bug|entropy|seed|predictable|weak)',
                r'crypto.*(?:fail|error|bug|primitive|implementation|side)',

                # æ•°æ®ç¼–ç è§£ç bug
                r'encoding.*(?:fail|error|bug|rlp|abi|calldata|pubdata)',
                r'decoding.*(?:fail|error|bug|parsing|validation|format)',
                r'serialization.*(?:fail|error|bug|format|version|compat)',
                r'compression.*(?:fail|error|bug|ratio|algorithm|data)',
                r'calldata.*(?:fail|error|bug|encoding|size|limit|cost)'
            ]

            zksync_bug_matches = []
            for pattern in zksync_bug_patterns:
                zksync_bug_matches.extend(re.findall(pattern, title_body_text))

            # è®¡ç®—åŒ¹é…åˆ†æ•°ï¼ˆä¸åŸç ”ç©¶æ–¹æ³•è®ºä¸€è‡´ï¼‰
            match_score = (len(general_keyword_matches) +
                           len(label_matches) +
                           len(fix_references) +
                           len(zksync_bug_matches))

            if general_keyword_matches or label_matches or fix_references or zksync_bug_matches:
                confidence = 'high' if match_score >= 3 else 'medium' if match_score >= 1 else 'low'

                bug_candidates.append({
                    **pr,
                    'general_keyword_matches': general_keyword_matches,
                    'zksync_keyword_matches': zksync_keyword_matches,
                    'label_matches': label_matches,
                    'fix_references': fix_references,
                    'zksync_bug_matches': zksync_bug_matches,
                    'match_score': match_score,
                    'confidence': confidence
                })

        print(f"âœ… ä» {len(merged_prs)} ä¸ªåˆå¹¶PRä¸­è¯†åˆ«å‡º {len(bug_candidates)} ä¸ªç–‘ä¼¼bugä¿®å¤PR")

        # æŒ‰ç½®ä¿¡åº¦åˆ†ç±»ç»Ÿè®¡
        high_confidence = len([c for c in bug_candidates if c['confidence'] == 'high'])
        medium_confidence = len([c for c in bug_candidates if c['confidence'] == 'medium'])
        low_confidence = len([c for c in bug_candidates if c['confidence'] == 'low'])

        print(f"   - é«˜ç½®ä¿¡åº¦: {high_confidence}")
        print(f"   - ä¸­ç½®ä¿¡åº¦: {medium_confidence}")
        print(f"   - ä½ç½®ä¿¡åº¦: {low_confidence}")

        # æŒ‰zkSync EraåŠŸèƒ½åˆ†ç±»ç»Ÿè®¡
        proof_bugs = len([c for c in bug_candidates if any('proof' in match or 'prover' in match or 'circuit' in match
                                                           for match in
                                                           c['zksync_keyword_matches'] + c['zksync_bug_matches'])])
        bridge_bugs = len(
            [c for c in bug_candidates if any('bridge' in match or 'deposit' in match or 'withdrawal' in match
                                              for match in c['zksync_keyword_matches'] + c['zksync_bug_matches'])])
        aa_bugs = len([c for c in bug_candidates if any('account' in match or 'paymaster' in match or 'userops' in match
                                                        for match in
                                                        c['zksync_keyword_matches'] + c['zksync_bug_matches'])])
        gas_bugs = len([c for c in bug_candidates if any('gas' in match or 'fee' in match or 'ergs' in match
                                                         for match in
                                                         c['zksync_keyword_matches'] + c['zksync_bug_matches'])])
        batch_bugs = len([c for c in bug_candidates if any('batch' in match or 'sequencer' in match or 'commit' in match
                                                           for match in
                                                           c['zksync_keyword_matches'] + c['zksync_bug_matches'])])

        print(f"   - ZKè¯æ˜ç›¸å…³bug: {proof_bugs}")
        print(f"   - æ¡¥æ¥ç›¸å…³bug: {bridge_bugs}")
        print(f"   - è´¦æˆ·æŠ½è±¡ç›¸å…³bug: {aa_bugs}")
        print(f"   - Gas/è´¹ç”¨ç›¸å…³bug: {gas_bugs}")
        print(f"   - æ‰¹æ¬¡å¤„ç†ç›¸å…³bug: {batch_bugs}")

        return bug_candidates

    def export_results(self, merged_prs, bug_candidates, stats):
        """å¯¼å‡ºç»“æœåˆ°Excel"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿ç›®å½•åˆ›å»º
        excel_dir = os.path.abspath(ZKSYNC_CONFIG['excel_output'])
        os.makedirs(excel_dir, exist_ok=True)

        excel_file = os.path.join(excel_dir, f"zksync_era_{timestamp}.xlsx")

        print(f"ğŸ“‚ æ­£åœ¨åˆ›å»ºExcelæ–‡ä»¶...")
        print(f"   ç›®å½•: {excel_dir}")
        print(f"   æ–‡ä»¶: zksync_era_{timestamp}.xlsx")

        try:
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                # 1. æ‰€æœ‰åˆå¹¶çš„PR
                merged_df = pd.DataFrame(merged_prs)
                merged_df.to_excel(writer, sheet_name='All_Merged_PRs', index=False)

                # 2. ç–‘ä¼¼bugä¿®å¤PR
                if bug_candidates:
                    bug_df = pd.DataFrame(bug_candidates)
                    # é€‰æ‹©é‡è¦åˆ—
                    bug_display_df = bug_df[[
                        'number', 'title', 'user', 'merged_at', 'match_score', 'confidence',
                        'general_keyword_matches', 'zksync_keyword_matches', 'label_matches',
                        'project_name', 'project_type', 'project_domain', 'url'
                    ]].copy()

                    # æ ¼å¼åŒ–åŒ¹é…ç»“æœ
                    bug_display_df['general_keyword_matches'] = bug_display_df['general_keyword_matches'].apply(
                        lambda x: ', '.join(x[:5]))
                    bug_display_df['zksync_keyword_matches'] = bug_display_df['zksync_keyword_matches'].apply(
                        lambda x: ', '.join(x[:5]))
                    bug_display_df['label_matches'] = bug_display_df['label_matches'].apply(lambda x: ', '.join(x))

                    bug_display_df.to_excel(writer, sheet_name='Bug_Fix_Candidates', index=False)

                # 3. ç»Ÿè®¡ä¿¡æ¯
                stats_data = [
                    ['é¡¹ç›®åç§°', 'zkSync Era'],
                    ['é¡¹ç›®ç±»å‹', 'Layer 2'],
                    ['é¡¹ç›®é¢†åŸŸ', 'Ethereum ZK-Rollup Scaling Solution'],
                    ['ä»“åº“åœ°å€', f"{self.owner}/{self.repo}"],
                    ['æ€»åˆå¹¶PRæ•°', stats['total_prs']],
                    ['ZKè¯æ˜ç›¸å…³PRæ•°', stats['zk_proof_prs']],
                    ['æ¡¥æ¥ç›¸å…³PRæ•°', stats['bridge_prs']],
                    ['è´¦æˆ·æŠ½è±¡ç›¸å…³PRæ•°', stats['aa_prs']],
                    ['Gas/è´¹ç”¨ç›¸å…³PRæ•°', stats['gas_prs']],
                    ['æ‰¹æ¬¡å¤„ç†ç›¸å…³PRæ•°', stats['batch_prs']],
                    ['å‡çº§æ²»ç†ç›¸å…³PRæ•°', stats['upgrade_prs']],
                    ['ç–‘ä¼¼bugä¿®å¤PRæ•°', len(bug_candidates)],
                    ['æœ€æ´»è·ƒè´¡çŒ®è€…', stats['user_counts'].index[0] if not stats['user_counts'].empty else 'N/A'],
                    ['æ€»ä»£ç å¢åŠ è¡Œæ•°', stats['code_stats']['additions']],
                    ['æ€»ä»£ç åˆ é™¤è¡Œæ•°', stats['code_stats']['deletions']],
                    ['æ€»å˜æ›´æ–‡ä»¶æ•°', stats['code_stats']['files']]
                ]

                stats_df = pd.DataFrame(stats_data, columns=['æŒ‡æ ‡', 'æ•°å€¼'])
                stats_df.to_excel(writer, sheet_name='Statistics', index=False)

                # 4. æ—¶é—´è¶‹åŠ¿
                time_df = stats['date_counts'].reset_index()
                time_df.columns = ['æ—¥æœŸ', 'PRæ•°é‡']
                time_df.to_excel(writer, sheet_name='Time_Trends', index=False)

                # 5. ç½®ä¿¡åº¦åˆ†å¸ƒ
                if bug_candidates:
                    confidence_counts = pd.Series([c['confidence'] for c in bug_candidates]).value_counts()
                    confidence_df = confidence_counts.reset_index()
                    confidence_df.columns = ['ç½®ä¿¡åº¦', 'æ•°é‡']
                    confidence_df.to_excel(writer, sheet_name='Confidence_Distribution', index=False)

                # 6. zkSync EraåŠŸèƒ½åˆ†ç±»
                if bug_candidates:
                    function_data = []
                    for candidate in bug_candidates:
                        functions = []
                        matches = candidate['zksync_keyword_matches'] + candidate['zksync_bug_matches']

                        if any('proof' in match or 'prover' in match or 'circuit' in match for match in matches):
                            functions.append('ZK_Proof')
                        if any('bridge' in match or 'deposit' in match or 'withdrawal' in match for match in matches):
                            functions.append('Bridge')
                        if any('account' in match or 'paymaster' in match or 'userops' in match for match in matches):
                            functions.append('Account_Abstraction')
                        if any('gas' in match or 'fee' in match or 'ergs' in match for match in matches):
                            functions.append('Gas_Fee')
                        if any('batch' in match or 'sequencer' in match or 'commit' in match for match in matches):
                            functions.append('Batch_Processing')
                        if any('upgrade' in match or 'governance' in match or 'diamond' in match for match in matches):
                            functions.append('Upgrade_Governance')

                        function_data.append({
                            'PR_Number': candidate['number'],
                            'Title': candidate['title'],
                            'Functions': ', '.join(functions) if functions else 'General',
                            'Confidence': candidate['confidence']
                        })

                    function_df = pd.DataFrame(function_data)
                    function_df.to_excel(writer, sheet_name='Function_Classification', index=False)

            # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„åˆ›å»ºæˆåŠŸ
            if os.path.exists(excel_file):
                file_size = os.path.getsize(excel_file)
                print(f"âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼")
                print(f"   å¤§å°: {file_size:,} bytes")
            else:
                print(f"âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºExcelæ—¶å‡ºé”™: {e}")
            excel_file = None

        print(f"ğŸ“ zkSync Eraç»“æœå·²å¯¼å‡ºåˆ°: {excel_file}")
        print(f"ğŸ“‚ å®Œæ•´è·¯å¾„: {os.path.abspath(excel_file) if excel_file else 'N/A'}")
        return excel_file

    def make_request(self, url, params=None):
        """å‘é€APIè¯·æ±‚"""
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 403:
                print("âš ï¸  APIé…é¢å¯èƒ½ä¸è¶³ï¼Œè¯·ç¨åé‡è¯•")
                return None
            else:
                print(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
        except Exception as e:
            print(f"è¯·æ±‚å¼‚å¸¸: {e}")
            return None

    def run_collection(self):
        """è¿è¡Œå®Œæ•´çš„æ”¶é›†æµç¨‹"""
        print("ğŸš€ å¼€å§‹æ”¶é›†zkSync Eraå·²åˆå¹¶çš„PR...")
        print("ğŸ“– å®éªŒæµç¨‹ï¼šä¸“é—¨åˆ†æSolidityæ™ºèƒ½åˆçº¦ä»“åº“")
        print("ğŸ”— é¡¹ç›®ï¼šzkSync Era - é›¶çŸ¥è¯†è¯æ˜ä»¥å¤ªåŠLayer 2æ‰©å®¹æ–¹æ¡ˆ")
        print(f"ğŸ“ ä»“åº“ï¼š{self.owner}/{self.repo}")

        # 1. æ”¶é›†æ‰€æœ‰å·²åˆå¹¶çš„PR
        merged_prs = self.collect_all_merged_prs()

        if not merged_prs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å·²åˆå¹¶çš„PR")
            return

        # 2. åˆ†æPRæ•°æ®
        stats = self.analyze_merged_prs(merged_prs)

        # 3. è¯†åˆ«bugä¿®å¤ç›¸å…³çš„PR
        bug_candidates = self.identify_bug_fix_prs(merged_prs)

        # 4. å¯¼å‡ºç»“æœ
        excel_file = self.export_results(merged_prs, bug_candidates, stats)

        print(f"\nâœ… zkSync Eraæ•°æ®æ”¶é›†å®Œæˆï¼")
        print(f"ğŸ“Š ç»“æœæ‘˜è¦:")
        print(f"   - é¡¹ç›®: zkSync Era")
        print(f"   - ç±»å‹: Layer 2")
        print(f"   - é¢†åŸŸ: Ethereum ZK-Rollup Scaling Solution")
        print(f"   - æ€»åˆå¹¶PR: {len(merged_prs)}")
        print(f"   - ZKè¯æ˜åŠŸèƒ½PR: {stats['zk_proof_prs']}")
        print(f"   - æ¡¥æ¥åŠŸèƒ½PR: {stats['bridge_prs']}")
        print(f"   - è´¦æˆ·æŠ½è±¡åŠŸèƒ½PR: {stats['aa_prs']}")
        print(f"   - Gas/è´¹ç”¨åŠŸèƒ½PR: {stats['gas_prs']}")
        print(f"   - æ‰¹æ¬¡å¤„ç†åŠŸèƒ½PR: {stats['batch_prs']}")
        print(f"   - å‡çº§æ²»ç†åŠŸèƒ½PR: {stats['upgrade_prs']}")
        print(f"   - ç–‘ä¼¼bugä¿®å¤: {len(bug_candidates)}")
        print(f"   - ç»“æœæ–‡ä»¶: {excel_file}")

        # æ˜¾ç¤ºé¡¹ç›®ç›®å½•ç»“æ„
        print(f"\nğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•ç»“æ„:")
        output_base = os.path.abspath('./output')
        if os.path.exists(output_base):
            for root, dirs, files in os.walk(output_base):
                level = root.replace(output_base, '').count(os.sep)
                indent = ' ' * 2 * level
                print(f"{indent}{os.path.basename(root)}/")
                subindent = ' ' * 2 * (level + 1)
                for file in files:
                    print(f"{subindent}{file}")

        print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print(f"   1. äººå·¥å®¡æ ¸ç–‘ä¼¼bugä¿®å¤PRåˆ—è¡¨")
        print(f"   2. ç¡®è®¤çœŸæ­£çš„bugä¿®å¤å®ä¾‹")
        print(f"   3. æŒ‰8ç§bugç±»å‹è¿›è¡Œåˆ†ç±»")
        print(f"   4. åˆ†æLayer 2 ZK-Rollupçš„ç‰¹æœ‰bugæ¨¡å¼")
        print(f"   5. é‡ç‚¹å…³æ³¨è¯æ˜ç³»ç»Ÿã€æ¡¥æ¥ã€è´¦æˆ·æŠ½è±¡ã€Gasæœºåˆ¶ç­‰æ¨¡å—")


if __name__ == "__main__":
    collector = zkSyncEraCollector()
    collector.run_collection()