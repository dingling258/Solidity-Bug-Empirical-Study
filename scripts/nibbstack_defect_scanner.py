import sys
import os
import requests
import pandas as pd
import re
from datetime import datetime

# è·¯å¾„å¤„ç†ï¼šç¡®ä¿èƒ½å¯¼å…¥ config
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from config.settings_template import GITHUB_TOKEN, NIBBSTACK_CONFIG


class NibbstackDefectAnalyzer:
    def __init__(self):
        self.headers = {'Authorization': f'token {GITHUB_TOKEN}'}
        self.owner = NIBBSTACK_CONFIG['owner']
        self.repo = NIBBSTACK_CONFIG['repo']
        self.base_url = f"https://api.github.com/repos/{self.owner}/{self.repo}"

        # --- 1. ç»å¯¹é»‘åå• (Veto Keywords) ---
        # æ’é™¤æ„å»ºå·¥å…·ã€æ–‡æ¡£ã€æ ¼å¼åŒ–ç­‰éä»£ç é€»è¾‘ä¿®æ”¹
        self.veto_keywords = [
            r'\btypo\b', r'\bcomment\b', r'\bdoc(s)?\b', r'\bdocumentation\b',
            r'\btest(s)?\b', r'\btesting\b', r'\bcoverage\b',
            r'\bchore\b', r'\blint\b', r'\bprettier\b', r'\beslint\b',
            r'\bci\b', r'\bgithub\b', r'\bworkflow\b',
            r'\bbump\b', r'\bversion\b', r'\bdependency\b',
            r'\breadme\b', r'\blicense\b', r'\bignore\b', r'\bconfig\b'
        ]

        # --- 2. Tier 1: å¼ºä¿®å¤å…³é”®è¯ (æ ‡é¢˜ - é«˜æƒé‡ +10) ---
        self.tier1_keywords = [
            'fix', 'fixed', 'fixes', 'fixing',
            'patch', 'patched',
            'bug', 'bugs',
            'exploit', 'vulnerability',
            'revert', 'restore',  # å›æ»šé€šå¸¸æ„å‘³ç€ä¹‹å‰çš„ä»£ç æœ‰é—®é¢˜
            'critical', 'urgent',
            'prevent', 'avoid'
        ]

        # --- 3. Tier 2: ç¼ºé™·ç—‡çŠ¶ä¸åˆçº¦é€»è¾‘ (æ ‡é¢˜ - ä¸­æƒé‡ +5) ---
        # é’ˆå¯¹ Token æ ‡å‡†å®ç°çš„å¸¸è§é—®é¢˜
        self.tier2_keywords = [
            'fail', 'failure', 'error', 'incorrect', 'wrong',
            'revert', 'exception', 'throw',
            'gas', 'optimize', 'optimization',  # æ¿€è¿›çš„ä¼˜åŒ–å¸¸å¯¼è‡´Bug
            'overflow', 'underflow', 'safe', 'unsafe',
            'check', 'validate', 'require', 'assert',
            'compliance', 'standard', 'eip',  # ä¿®å¤ä¸ç¬¦åˆæ ‡å‡†çš„é—®é¢˜
            'emit', 'event', 'log'  # ä¿®å¤äº‹ä»¶ä¸¢å¤±
        ]

        # --- 4. Tier 3: å¼±å…³é”®è¯ (æ­£æ–‡ - ä½æƒé‡ +2) ---
        self.tier3_keywords = [
            'issue', 'problem', 'address', 'logic', 'behavior', 'handling'
        ]

        # --- 5. ERC721 ä¸Šä¸‹æ–‡å…³é”®è¯ (å¾®é‡åŠ åˆ† +2) ---
        # ç¡®è®¤ä¿®æ”¹å‘ç”Ÿåœ¨ NFT æ ¸å¿ƒé€»è¾‘ä¸­
        self.context_keywords = [
            'transfer', 'transferfrom', 'safetransfer',
            'approve', 'approval', 'setapprovalforall', 'getapproved', 'operator',
            'owner', 'ownable', 'ownership',
            'mint', 'burn',
            'balance', 'balanceof',
            'uri', 'tokenuri', 'baseuri', 'metadata',
            'receiver', 'onerc721received',  # æ¥æ”¶é’©å­ï¼ˆé‡å…¥æ”»å‡»é«˜å‘åŒºï¼‰
            'enumerable', 'supply', 'index'
        ]

    def fetch_all_merged_prs(self):
        """è·å–æ‰€æœ‰å·²åˆå¹¶PR"""
        print(f"ğŸš€ å¼€å§‹æ‰«æ {self.owner}/{self.repo} ...")
        all_merged_prs = []
        page = 1

        while True:
            print(f"   æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µ (æŒ‰æ›´æ–°æ—¶é—´å€’åº)...")
            params = {
                'state': 'closed',
                'per_page': 100,
                'page': page,
                'sort': 'updated',
                'direction': 'desc'
            }
            try:
                resp = requests.get(f"{self.base_url}/pulls", headers=self.headers, params=params, timeout=30)
                if resp.status_code != 200:
                    print(f"âš ï¸ API Error: {resp.status_code}")
                    break

                items = resp.json()
                if not items:
                    break

                for item in items:
                    if item.get('merged_at'):
                        pr_data = {
                            'number': item['number'],
                            'title': item['title'],
                            'body': item.get('body', '') or '',
                            'state': item['state'],
                            'merged_at': item['merged_at'],
                            'created_at': item['created_at'],
                            'user': item['user']['login'],
                            'url': item['html_url'],
                            'labels': [l['name'] for l in item.get('labels', [])]
                        }
                        all_merged_prs.append(pr_data)

                if len(items) < 100:
                    break
                page += 1
            except Exception as e:
                print(f"âŒ ç½‘ç»œé”™è¯¯: {e}")
                break

        print(f"ğŸ“¥ å…±è·å– {len(all_merged_prs)} ä¸ªå·²åˆå¹¶ PRã€‚")
        return all_merged_prs

    def analyze_pr(self, pr):
        """
        æ ¸å¿ƒç­›é€‰é€»è¾‘
        """
        title = pr['title']
        body = pr['body']
        labels = [l.lower() for l in pr['labels']]

        title_lower = title.lower()
        body_lower = body.lower()

        score = 0
        reasons = []

        # --- Step 1: ç»å¯¹å¦å†³ (Veto) ---
        for pattern in self.veto_keywords:
            if re.search(pattern, title_lower):
                return 0, [f"VETO: Title matches {pattern}"], True

        # --- Step 2: æ ‡é¢˜åˆ†æ (é«˜æƒé‡) ---
        # Tier 1
        for kw in self.tier1_keywords:
            if re.search(r'\b' + kw + r'\b', title_lower):
                score += 10
                reasons.append(f"Title(Tier1): {kw}")
                break

                # Tier 2
        for kw in self.tier2_keywords:
            if re.search(r'\b' + kw + r'\b', title_lower):
                score += 5
                reasons.append(f"Title(Tier2): {kw}")
                break

        # --- Step 3: æ­£æ–‡è¡¥æ•‘ (Body Fallback) ---
        if score < 10:
            # æŸ¥æ‰¾ Issue å¼•ç”¨
            if re.search(r'(fix|close|resolve)(e?s)?\s+#\d+', body_lower):
                score += 5
                reasons.append("Body: References Issue ID")

            # æ­£æ–‡å‰æ®µæŸ¥æ‰¾å¼ºå…³é”®è¯
            intro_body = body_lower[:500]
            for kw in self.tier1_keywords:
                if re.search(r'\b' + kw + r'\b', intro_body):
                    score += 2
                    reasons.append(f"Body(Intro): {kw}")
                    break

        # --- Step 4: æ ‡ç­¾åŠ æˆ (Labels) ---
        bug_labels = ['bug', 'defect', 'security', 'invalid']  # invalid å¯èƒ½æ˜¯ "invalid logic"
        for label in labels:
            if any(bl in label for bl in bug_labels):
                score += 10
                reasons.append(f"Label: {label}")

        # --- Step 5: ä¸Šä¸‹æ–‡åŠ æˆ (Context) ---
        # é’ˆå¯¹ ERC721 ç‰¹æœ‰é€»è¾‘åŠ åˆ†
        context_hits = [k for k in self.context_keywords if k in title_lower]
        if context_hits and score > 0:
            score += 2
            reasons.append(f"Context: {context_hits[0]}")

        return score, reasons, False

    def run(self):
        # 1. è·å–æ•°æ®
        all_prs = self.fetch_all_merged_prs()

        defect_candidates = []
        veto_count = 0
        low_score_count = 0

        # 2. åˆ†æ
        print("ğŸ•µï¸ æ­£åœ¨åº”ç”¨åŠ æƒç­›é€‰é€»è¾‘...")
        for pr in all_prs:
            score, reasons, is_vetoed = self.analyze_pr(pr)

            pr['analysis_score'] = score
            pr['analysis_reasons'] = " | ".join(reasons)
            pr['is_vetoed'] = is_vetoed

            if is_vetoed:
                veto_count += 1
                continue

            if score >= NIBBSTACK_CONFIG['min_score_threshold']:
                confidence = "High" if score >= 15 else ("Medium" if score >= 10 else "Low")

                candidate = {
                    'PR Number': pr['number'],
                    'Score': score,
                    'Confidence': confidence,
                    'Title': pr['title'],
                    'Reasons': pr['analysis_reasons'],
                    'Merged At': pr['merged_at'],
                    'URL': pr['url'],
                    'User': pr['user'],
                    'Body Snippet': pr['body'][:200].replace('\n', ' ')
                }
                defect_candidates.append(candidate)
            else:
                low_score_count += 1

        # æ’åº
        defect_candidates.sort(key=lambda x: (x['Score'], x['Merged At']), reverse=True)

        # 3. å¯¼å‡º
        self.export(all_prs, defect_candidates, veto_count, low_score_count)

    def export(self, all_prs, candidates, vetoed, low_score):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"nibbstack_defects_{timestamp}.xlsx"
        output_path = os.path.join(NIBBSTACK_CONFIG['excel_output'], filename)

        os.makedirs(NIBBSTACK_CONFIG['excel_output'], exist_ok=True)

        print(f"ğŸ’¾ æ­£åœ¨å¯¼å‡º Excel åˆ° {output_path} ...")

        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # Sheet 1: ç¼ºé™·å€™é€‰
                if candidates:
                    df_candidates = pd.DataFrame(candidates)
                    df_candidates.to_excel(writer, sheet_name='Defect_Candidates', index=False)
                else:
                    pd.DataFrame(["æ— ç¬¦åˆæ¡ä»¶çš„PR"]).to_excel(writer, sheet_name='Defect_Candidates')

                # Sheet 2: æ‰€æœ‰å·²åˆå¹¶PR
                df_all = pd.DataFrame(all_prs)
                cols = ['number', 'title', 'analysis_score', 'is_vetoed', 'merged_at', 'user', 'url', 'labels',
                        'analysis_reasons']
                existing_cols = [c for c in cols if c in df_all.columns]
                df_all = df_all[existing_cols]
                df_all.to_excel(writer, sheet_name='All_Merged_PRs', index=False)

                # Sheet 3: ç»Ÿè®¡
                stats_data = [
                    ['é¡¹ç›®', 'nibbstack/erc721'],
                    ['æ€»å·²åˆå¹¶PR', len(all_prs)],
                    ['ğŸš« è¢«å¦å†³ (Tooling/Doc)', vetoed],
                    ['ğŸ“‰ ä½åˆ† (Feature/Refactor)', low_score],
                    ['âœ… ç–‘ä¼¼ç¼ºé™· (Candidates)', len(candidates)],
                    ['ç­›é€‰é˜ˆå€¼', NIBBSTACK_CONFIG['min_score_threshold']]
                ]
                pd.DataFrame(stats_data, columns=['Metric', 'Value']).to_excel(writer, sheet_name='Statistics',
                                                                               index=False)

            print("âœ… å¯¼å‡ºå®Œæˆï¼")
            print(f"   - ç¼ºé™·å€™é€‰: {len(candidates)} æ¡")
            print(f"   - å…¨é‡PR: {len(all_prs)} æ¡")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")


if __name__ == "__main__":
    analyzer = NibbstackDefectAnalyzer()
    analyzer.run()