import sys
import os
import requests
import pandas as pd
import re
from datetime import datetime

# è·¯å¾„å¤„ç†ï¼šç¡®ä¿èƒ½å¯¼å…¥ config
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from config.settings_template import GITHUB_TOKEN, THIRDWEB_CONFIG


class ThirdwebDefectAnalyzer:
    def __init__(self):
        self.headers = {'Authorization': f'token {GITHUB_TOKEN}'}
        self.owner = THIRDWEB_CONFIG['owner']
        self.repo = THIRDWEB_CONFIG['repo']
        self.base_url = f"https://api.github.com/repos/{self.owner}/{self.repo}"

        # --- 1. ç»å¯¹é»‘åå• (Veto Keywords) ---
        # Thirdweb ä»“åº“ä¸­åŒ…å«å¤§é‡ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç ï¼Œéœ€ä¸¥æ ¼è¿‡æ»¤
        self.veto_keywords = [
            r'\btypo\b', r'\bcomment\b', r'\bdoc(s)?\b', r'\bdocumentation\b',
            r'\bfuzz\b', r'\btest(s)?\b', r'\btesting\b', r'\bbenchmark\b',
            r'\bchore\b', r'\blint\b', r'\bstyle\b', r'\bformat\b',
            r'\bci\b', r'\bworkflow\b', r'\bbump\b', r'\bversion\b',
            r'\brelease\b', r'\bmerge\b', r'\bexample\b', r'\bsample\b',
            r'\blicense\b', r'\breadme\b', r'\bmakefile\b', r'\bscript\b'
        ]

        # --- 2. Tier 1: å¼ºä¿®å¤å…³é”®è¯ (æ ‡é¢˜ - é«˜æƒé‡ +10) ---
        self.tier1_keywords = [
            'fix', 'fixed', 'fixes', 'fixing',
            'patch', 'patched',
            'resolve', 'resolved',
            'bug', 'bugs',
            'vulnerability', 'exploit', 'hack',
            'prevent', 'prevention',
            'hotfix', 'critical',
            'restore', 'revert'
        ]

        # --- 3. Tier 2: ç¼ºé™·ç—‡çŠ¶ä¸åˆçº¦é€»è¾‘ (æ ‡é¢˜ - ä¸­æƒé‡ +5) ---
        self.tier2_keywords = [
            'incorrect', 'correct', 'correction',
            'wrong', 'fail', 'failure', 'failed', 'error',
            'crash', 'panic', 'stuck', 'broken',
            'validate', 'validation', 'check', 'require', 'assert',
            'gas', 'optimize', 'optimization',  # Gas ä¼˜åŒ–
            'leak', 'overflow', 'underflow',
            'permission', 'access', 'auth', 'role',  # æƒé™æ§åˆ¶
            'modifier', 'event', 'emit',
            'unsafe', 'unchecked', 'reentrancy'
        ]

        # --- 4. Tier 3: å¼±å…³é”®è¯ (æ­£æ–‡ - ä½æƒé‡ +2) ---
        self.tier3_keywords = [
            'issue', 'problem', 'change', 'update', 'modify', 'logic', 'address'
        ]

        # --- 5. Thirdweb ä¸Šä¸‹æ–‡å…³é”®è¯ (å¾®é‡åŠ åˆ† +2) ---
        # é’ˆå¯¹ Thirdweb çš„ç‰¹æœ‰åŠŸèƒ½æ¨¡å—
        self.context_keywords = [
            # æ ¸å¿ƒæ¶æ„
            'factory', 'registry', 'router', 'platform', 'extension', 'plugin',
            'proxy', 'implementation', 'upgrade', 'clone',
            # ä¸šåŠ¡åŠŸèƒ½
            'drop', 'marketplace', 'edition', 'pack', 'split', 'vote', 'multiwrap',
            'token', 'nft', 'erc721', 'erc1155', 'erc20',
            # å…·ä½“æœºåˆ¶
            'claim', 'mint', 'signature', 'sig', 'lazy', 'reveal', 'metadata',
            'royalty', 'royalties', 'primary', 'secondary', 'sale',
            'merkle', 'proof', 'allowlist', 'snapshot'
        ]

    def fetch_all_merged_prs(self):
        """è·å–æ‰€æœ‰å·²åˆå¹¶PR"""
        print(f"ğŸš€ å¼€å§‹æ‰«æ {self.owner}/{self.repo} ...")
        all_merged_prs = []
        page = 1

        while True:
            print(f"   æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µ (æŒ‰æ›´æ–°æ—¶é—´å€’åº)...")
            params = {
                'state': 'closed',
                'per_page': 100,
                'page': page,
                'sort': 'updated',
                'direction': 'desc'
            }
            try:
                resp = requests.get(f"{self.base_url}/pulls", headers=self.headers, params=params, timeout=30)
                if resp.status_code != 200:
                    print(f"âš ï¸ API Error: {resp.status_code}")
                    break

                items = resp.json()
                if not items:
                    break

                for item in items:
                    if item.get('merged_at'):  # åªä¿ç•™å·²åˆå¹¶çš„
                        pr_data = {
                            'number': item['number'],
                            'title': item['title'],
                            'body': item.get('body', '') or '',
                            'state': item['state'],
                            'merged_at': item['merged_at'],
                            'created_at': item['created_at'],
                            'user': item['user']['login'],
                            'url': item['html_url'],
                            'labels': [l['name'] for l in item.get('labels', [])]
                        }
                        all_merged_prs.append(pr_data)

                if len(items) < 100:
                    break
                page += 1
            except Exception as e:
                print(f"âŒ ç½‘ç»œé”™è¯¯: {e}")
                break

        print(f"ğŸ“¥ å…±è·å– {len(all_merged_prs)} ä¸ªå·²åˆå¹¶ PRã€‚")
        return all_merged_prs

    def analyze_pr(self, pr):
        """
        æ ¸å¿ƒç­›é€‰é€»è¾‘ï¼šåˆ†å±‚åŠ æƒ
        """
        title = pr['title']
        body = pr['body']
        labels = [l.lower() for l in pr['labels']]

        title_lower = title.lower()
        body_lower = body.lower()

        score = 0
        reasons = []

        # --- Step 1: ç»å¯¹å¦å†³ (Veto) ---
        for pattern in self.veto_keywords:
            if re.search(pattern, title_lower):
                return 0, [f"VETO: Title matches {pattern}"], True

        # --- Step 2: æ ‡é¢˜åˆ†æ (é«˜æƒé‡) ---
        # Tier 1: å¼ºä¿®å¤ (+10)
        for kw in self.tier1_keywords:
            if re.search(r'\b' + kw + r'\b', title_lower):
                score += 10
                reasons.append(f"Title(Tier1): {kw}")
                break

                # Tier 2: é€»è¾‘/ç—‡çŠ¶ (+5)
        for kw in self.tier2_keywords:
            if re.search(r'\b' + kw + r'\b', title_lower):
                score += 5
                reasons.append(f"Title(Tier2): {kw}")
                break

        # --- Step 3: æ­£æ–‡è¡¥æ•‘ (Body Fallback) ---
        # ä»…å½“æ ‡é¢˜åˆ†æ•°ä¸è¶³ 10 åˆ†æ—¶å¯ç”¨
        if score < 10:
            # æŸ¥æ‰¾ Issue å¼•ç”¨ (+5)
            if re.search(r'(fix|close|resolve)(e?s)?\s+#\d+', body_lower):
                score += 5
                reasons.append("Body: References Issue ID")

            # æ­£æ–‡å‰500å­—ç¬¦æŸ¥æ‰¾å¼ºå…³é”®è¯ (+2)
            intro_body = body_lower[:500]
            for kw in self.tier1_keywords:
                if re.search(r'\b' + kw + r'\b', intro_body):
                    score += 2
                    reasons.append(f"Body(Intro): {kw}")
                    break

        # --- Step 4: æ ‡ç­¾åŠ æˆ (Labels) ---
        bug_labels = ['bug', 'defect', 'security', 'high', 'critical', 'invalid']
        for label in labels:
            if any(bl in label for bl in bug_labels):
                score += 10
                reasons.append(f"Label: {label}")

        # --- Step 5: ä¸Šä¸‹æ–‡åŠ æˆ (Context) ---
        # ä»…åœ¨å·²æœ‰åŸºç¡€åˆ†(>0)çš„æƒ…å†µä¸‹åŠ åˆ†ï¼Œç¡®è®¤ä¿®æ”¹å‘ç”Ÿåœ¨æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ä¸­
        context_hits = [k for k in self.context_keywords if k in title_lower]
        if context_hits and score > 0:
            score += 2
            reasons.append(f"Context: {context_hits[0]}")

        return score, reasons, False

    def run(self):
        # 1. è·å–æ•°æ®
        all_prs = self.fetch_all_merged_prs()

        defect_candidates = []
        veto_count = 0
        low_score_count = 0

        # 2. åˆ†æ
        print("ğŸ•µï¸ æ­£åœ¨åº”ç”¨åŠ æƒç­›é€‰é€»è¾‘...")
        for pr in all_prs:
            score, reasons, is_vetoed = self.analyze_pr(pr)

            # è®°å½•åˆ†æç»“æœåˆ°åŸå§‹å¯¹è±¡
            pr['analysis_score'] = score
            pr['analysis_reasons'] = " | ".join(reasons)
            pr['is_vetoed'] = is_vetoed

            if is_vetoed:
                veto_count += 1
                continue

            if score >= THIRDWEB_CONFIG['min_score_threshold']:
                confidence = "High" if score >= 15 else ("Medium" if score >= 10 else "Low")

                candidate = {
                    'PR Number': pr['number'],
                    'Score': score,
                    'Confidence': confidence,
                    'Title': pr['title'],
                    'Reasons': pr['analysis_reasons'],
                    'Merged At': pr['merged_at'],
                    'URL': pr['url'],
                    'User': pr['user'],
                    'Body Snippet': pr['body'][:200].replace('\n', ' ')
                }
                defect_candidates.append(candidate)
            else:
                low_score_count += 1

        # æ’åºï¼šåˆ†æ•°é«˜åœ¨å‰ï¼Œæ—¶é—´æ–°åœ¨å‰
        defect_candidates.sort(key=lambda x: (x['Score'], x['Merged At']), reverse=True)

        # 3. å¯¼å‡º
        self.export(all_prs, defect_candidates, veto_count, low_score_count)

    def export(self, all_prs, candidates, vetoed, low_score):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"thirdweb_defects_{timestamp}.xlsx"
        output_path = os.path.join(THIRDWEB_CONFIG['excel_output'], filename)

        os.makedirs(THIRDWEB_CONFIG['excel_output'], exist_ok=True)

        print(f"ğŸ’¾ æ­£åœ¨å¯¼å‡º Excel åˆ° {output_path} ...")

        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # Sheet 1: ç¼ºé™·å€™é€‰
                if candidates:
                    df_candidates = pd.DataFrame(candidates)
                    df_candidates.to_excel(writer, sheet_name='Defect_Candidates', index=False)
                else:
                    pd.DataFrame(["æ— ç¬¦åˆæ¡ä»¶çš„PR"]).to_excel(writer, sheet_name='Defect_Candidates')

                # Sheet 2: æ‰€æœ‰å·²åˆå¹¶PR
                df_all = pd.DataFrame(all_prs)
                cols = ['number', 'title', 'analysis_score', 'is_vetoed', 'merged_at', 'user', 'url', 'labels',
                        'analysis_reasons']
                existing_cols = [c for c in cols if c in df_all.columns]
                df_all = df_all[existing_cols]
                df_all.to_excel(writer, sheet_name='All_Merged_PRs', index=False)

                # Sheet 3: ç»Ÿè®¡
                stats_data = [
                    ['é¡¹ç›®', 'thirdweb-dev/contracts'],
                    ['æ€»å·²åˆå¹¶PR', len(all_prs)],
                    ['ğŸš« è¢«å¦å†³ (Test/Doc/Example)', vetoed],
                    ['ğŸ“‰ ä½åˆ† (Feature/Refactor)', low_score],
                    ['âœ… ç–‘ä¼¼ç¼ºé™· (Candidates)', len(candidates)],
                    ['ç­›é€‰é˜ˆå€¼', THIRDWEB_CONFIG['min_score_threshold']]
                ]
                pd.DataFrame(stats_data, columns=['Metric', 'Value']).to_excel(writer, sheet_name='Statistics',
                                                                               index=False)

            print("âœ… å¯¼å‡ºå®Œæˆï¼")
            print(f"   - ç¼ºé™·å€™é€‰: {len(candidates)} æ¡")
            print(f"   - å…¨é‡PR: {len(all_prs)} æ¡")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")


if __name__ == "__main__":
    analyzer = ThirdwebDefectAnalyzer()
    analyzer.run()